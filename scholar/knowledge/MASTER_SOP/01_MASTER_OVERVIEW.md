# PT STUDY SOP - MASTER OVERVIEW v9.3
**Compiled:** January 2026  
**Source:** Full repo audit of C:\pt-study-sop

---

## EXECUTIVE SUMMARY

This system is an AI-assisted study methodology built on evidence-based learning science. It enforces active learning through structured protocols, gated progression, and spaced retrieval.

**Core Principles:**
1. User generates, AI validates (no passive consumption)
2. Function before structure (know what it DOES before what it IS)
3. Gated progression (demonstrate understanding before advancing)
4. Source-locked teaching (no factual claims without verified sources)
5. Desirable difficulties (struggle with feedback builds retention)

---

## PART 1: LEARNING CYCLE

### PEIRRO (Core Learning Module)
The backbone cycle for all study sessions:

| Phase | Purpose | Key Action |
|-------|---------|------------|
| **Prepare** | Orient attention | Clarify scope, relevance, expectations |
| **Encode** | Build schemas | Link new to prior knowledge; KWIK lives here |
| **Interrogate** | Deepen understanding | Ask "why/how" during encoding |
| **Retrieve** | Strengthen memory | Effortful recall without cues |
| **Refine** | Fix errors | Correct misconceptions from retrieval feedback |
| **Overlearn** | Stabilize | Continued spaced recall past mastery |

**Rule:** Do not skip phases in full sessions.

---

### KWIK (Encoding Flow)
Used during Encode phase to create durable memory hooks:

```
Sound → Function → Image → Resonance → Lock
```

| Step | Action | Gate |
|------|--------|------|
| Sound | Phonetic seed/sound-alike | User provides |
| Function | State true action FIRST | Before imagery |
| Image | Visual tied to function | After meaning confirmed |
| Resonance | "Sounds right, feels right" | User confirms |
| Lock | Record card/hook | Only after resonance |

**Critical Rule:** Word + Meaning BEFORE imagery. Never skip resonance.

---

## PART 2: SESSION PHASES (M-Series)

### M0: Planning (MANDATORY)
> "No teaching until: target, sources, plan, and pre-test are confirmed."

**Protocol:**
1. **TARGET:** Exam/block + time available
2. **POSITION:** Covered vs remaining; weak spots
3. **MATERIALS:** LOs, slides, labs, practice Qs
4. **SOURCE-LOCK:** Specific pages/files for today
5. **INTERLEAVE:** Review 1-2 weak anchors from prior session
6. **PLAN:** 3-5 steps
7. **GLOSSARY SCAN:** Top 5 terms; define at L2
8. **PRIME:** 1-3 pre-questions or brain dump

---

### M1: Entry
**Purpose:** Initialize session state and select mode.

**Checklist:**
- Focus level (1-10)
- Energy/motivation
- Topic + materials + time
- Mode selection
- Load prior context if resuming

---

### M2: Prime
**Purpose:** Map territory before encoding. Build buckets, don't memorize.

**Protocol:**
1. H1 scan (≤6 bullets or 2 paragraphs)
2. User groups into 2-4 buckets
3. Select first bucket to encode
4. Run pre-questions if not done in M0

**Ingestion Sandwich (pre-lecture):**
- Scan headings, objectives, figures
- Write 5 pretest questions
- Note top 5 terms + 2-3 buckets

---

### M3: Encode
**Purpose:** Turn mapped buckets into understanding.

**Toolkit:**
- Dual code (words + visuals)
- Example → problem pairs (faded guidance)
- Self-explain prompts ("why/how")
- Segment & paraphrase
- Generate & check (predict → reveal)

**KWIK Flow:** Enforced for all memory hooks.

**Post-lecture (within 24h):**
- 3 why/how prompts
- 5 retrieval prompts from memory
- Cards for misses

---

### M4: Build
**Purpose:** Practice with spacing, interleaving, variability.

**Toolkit:**
- Interleave similar-but-different items
- Space key items (successive relearning: 2-3 correct recalls)
- Variability across contexts
- Progressive ladder: guided → partial → independent → spaced
- Error reflection: note each miss + correction

**Level Gating:** L2 teach-back required before L4 clinical detail.

**Fading (/fade):**
1. Worked example (full solution)
2. Completion problem (user finishes)
3. Independent problem (user solves fully)

---

### M5: Modes
| Mode | When | AI Behavior |
|------|------|-------------|
| **Core** | New material | Guide Prime→Encode→Build; scaffolds |
| **Sprint** | Has knowledge/exam prep | Test first; teach only on miss |
| **Drill** | Specific weak spot | User reconstructs; AI spots gaps |
| **Light** | 10-15 min | Micro: landmarks→attachments; 1-3 cards |
| **Quick Sprint** | 20-30 min | Timed burst; 3-5 cards required |

**Switch Heuristics:**
- Core → Sprint: ~80-90% confident
- Sprint → Drill: Repeated misses cluster
- Sprint → Core: Understanding shaky

---

### M6: Wrap (MANDATORY)
**Purpose:** Consolidation in 2-10 minutes.

**Exit Ticket (final 10 min):**
1. Free recall blurt (2 min, notes closed)
2. Muddiest point (one concept)
3. Next action hook

**Required Outputs:**
- Anki cards for misses/weak anchors
- Metrics: calibration gap, RSR%, cognitive load, transfer check
- Spaced retrieval schedule (1-3-7-21)
- Tracker JSON + Enhanced JSON

---

## PART 3: LEVEL GATING (4-10-HS-PT)

| Level | Target | Terms | Requirement |
|-------|--------|-------|-------------|
| L1 | Metaphor/Analogy | None | Always available |
| L2 | 10-Year-Old | Everyday | **GATE LEVEL** |
| L3 | High School | Some jargon | Requires L2 |
| L4 | Clinical/PT | Full precision | Requires L2 teach-back |

**Pattern:** Understand simply → Add complexity  
**NOT:** Hear complexity → Hope to understand

---

## PART 4: FRAMEWORKS

### H-Series (Priming/Mapping)
Used in M2 to expose structure before memorization.

| Framework | Pattern | Use Case |
|-----------|---------|----------|
| **H1** (default) | System→Subsystem→Component→Element | Any complex topic |
| **H2** | Structure→Function→Behavior→Outcome | Traditional anatomy (opt-in) |
| **H3** | Intrinsic→Extraneous→Germane | Diagnose cognitive load |
| **H4** | Bloom's depth ladder | Check target depth |
| **H5** | Passive→Active→Constructive→Interactive | Audit engagement |
| **H6** | Enactive→Iconic→Symbolic | Unstick with action→image→words |
| **H7** | Hook→Context→Conflict→Resolution | Writing/narratives |
| **H8** | Role→Task→Context→Constraint | Prompt framing |

---

### M-Series (Encoding/Logic)
Used in M3/M4 for function-first encoding.

| Framework | Pattern | Use Case |
|-----------|---------|----------|
| **M2** (default) | Trigger→Mechanism→Result→Implication | Processes, cause-effect |
| **M6** | Perturbation→Correction→Baseline | Regulation/feedback |
| **M8** | Cause→Mechanism→Sign→Test→Confirmation | Clinical/pathology |
| **M-SRL** | Forethought→Performance→Reflection | Self-regulated learning |
| **M-ADDIE** | Analyze→Design→Develop→Implement→Evaluate | Projects |
| **M-STAR** | Situation→Task→Action→Result | Resume/interviews |

---

### Y-Series (Quick Context)
Rapid orientation when M/H not enough.

| Framework | Pattern | Use Case |
|-----------|---------|----------|
| **Y1** | What is it→Does→Fails→Looks like | Fast orientation |
| **Y2** | Load→Response→Threshold→Outcome | Tissue adaptation |
| **Y3** | Deficit→Compensation→Side Effect | Movement patterns |
| **Y4** | Signal→Detection→Processing→Action | Neuro/physiology |

---

## PART 5: ENGINES

### Anatomy Engine
**Purpose:** Guided anatomy learning with bone/landmark-first sequencing.

**Mandatory Order (OIANA+):**
```
BONES → LANDMARKS → ATTACHMENTS (O/I) → ACTIONS → NERVES → ARTERIAL → CLINICAL
```

**Bone-First Attachment Loop:**
1. Select region (pelvis, posterior leg, etc.)
2. List exam-required bones and landmarks
3. Landmark pass (visual-first):
   - Visual: shape, size, texture
   - Spatial: position (anterior/posterior, medial/lateral)
   - Neighbors: nearby landmarks
   - Attachments: which muscles attach here
4. Build attachment map before OIANA+ details
5. Layer OIANA+ per muscle after map is solid
6. Add clinical patterns last

**Visual-First Landmark Protocol:**
- Recognition: what it looks like
- Orientation: where it is in 3D space
- Connection: what attaches here

**Arterial Step:** Capture primary artery per muscle; add recall Q.

**Rollback Rule:** If struggling with OIANA+, return to landmarks → attachments → re-layer.

**Commands:**
- `landmark` - Run landmark pass
- `draw` - Drawing instructions
- `mnemonic` - 3 options (after understanding)
- `wrap` - Recap + cards

---

### Concept Engine (Non-Anatomy)
**Purpose:** Default flow for abstract topics (law, coding, history).

**Order:**
1. **Definition:** L2 plain language + one-sentence hook
2. **Context:** Place in H1 map
3. **Mechanism:** Input→Process→Output
4. **Differentiation:** Example vs near-miss
5. **Application:** One problem; user solves; verify

**Protocol:** Wait → Generate → Validate (user attempts first)

**Commands:**
- `define` - Step 1
- `context` - Step 2
- `mechanism` - Step 3
- `compare` - Step 4
- `apply` - Step 5

---

## PART 6: WORKLOAD MANAGEMENT

### 3+2 Weekly Rotation
**Purpose:** Balance technical and reading-heavy classes with cross-review.

**Cluster Split:**
- Cluster A: 3 most technical classes
- Cluster B: 2 lighter/reading-heavy classes

**Weekly Rhythm:**
- Mon/Wed/Fri: Deep work Cluster A + 15 min review Cluster B
- Tue/Thu/Sat: Deep work Cluster B + 15 min review Cluster A
- Sunday: Weekly review + metacognition

---

### Ingestion Sandwich
**Pre-lecture (10-15 min):**
- Scan headings, objectives, figures
- Write 5 pretest questions (no answers yet)
- Write 1 prior-knowledge link
- Note top 5 terms + 2-3 buckets

**Active (during lecture):**
- Minimal structure map
- One small diagram
- One example + one boundary case
- Cornell notes (questions left, ideas right)

**Post-lecture (within 24h):**
- 3 why/how prompts
- 5 retrieval prompts from memory
- Cards for misses

---

### Spaced Retrieval (1-3-7-21)
**Default Schedule:**
- R1 = +1 day
- R2 = +3 days
- R3 = +7 days
- R4 = +21 days

**Adaptive Spacing (R/Y/G):**
- **Red** (struggled): Review sooner
- **Yellow** (effortful success): Keep standard
- **Green** (easy): Extend interval

**Successive Relearning:** 2-3 correct recalls before "mastered."

---

### Daily Playbooks
**10-15 min:**
- 1 micro target
- 3-5 retrieval prompts
- 1 exit ticket line

**20-30 min:**
- 1 small bucket
- 5-8 retrieval prompts
- 2-3 cards + exit ticket

**45-60 min:**
- 2-3 buckets
- 10-15 retrieval prompts
- Full exit ticket + schedule reviews

---

## PART 7: METRICS & LOGGING

### Exit Ticket (Final 10 min)
1. **Blurt:** 2 min free recall, notes closed
2. **Muddiest point:** One concept
3. **Next action hook:** First action for next session

### Study Metrics
| Metric | Definition |
|--------|------------|
| **Calibration Gap** | JOL (predicted) minus actual recall |
| **RSR %** | Retrieval success rate at session start |
| **Cognitive Load** | Dominant type: intrinsic/extraneous/germane |
| **Transfer Check** | Connected to another class? Y/N |

### Logging Schema (v9.3)
**Tracker JSON:** Basic session data  
**Enhanced JSON:** Full metrics + spaced review schedule

Required fields: date, topic, mode, duration, understanding, retention, calibration_gap, rsr_percent, cognitive_load, transfer_check, anchors, cards, exit_ticket, spaced_reviews

---

## PART 8: SOURCE VERIFICATION

### NotebookLM Bridge
**Hard Rule:** No factual/clinical claims without Source Packet.

**Source Packet Format:**
```
SOURCE PACKET (NotebookLM)
- Topic:
- Sources used:
- Key excerpts (with citations):
- Definitions:
- Mechanism/steps:
- Differentiators:
- Practice questions:
```

**NotebookLM Prompt:**
```
From my sources only: extract learning objectives, key definitions, 
mechanisms/steps, differentiators, and 5-10 practice questions; 
include citations.
```

---

## PART 9: COMMANDS REFERENCE

| Command | Action |
|---------|--------|
| `plan` | Start/review planning |
| `ready` | Next step |
| `bucket` | Group/organize |
| `mold` | Fix thinking |
| `wrap` | End session |
| `draw` | Drawing instructions |
| `landmark` | Run landmark pass |
| `rollback` | Back to earlier phase |
| `mode <x>` | Switch mode (core/sprint/drill/light/quick-sprint) |
| `mnemonic` | 3 options (after understanding) |
| `menu` | Show commands |
| `/fade` | Worked→Completion→Independent |
| `define` | Concept Engine step 1 |
| `context` | Concept Engine step 2 |
| `mechanism` | Concept Engine step 3 |
| `compare` | Concept Engine step 4 |
| `apply` | Concept Engine step 5 |

---

## PART 10: EVIDENCE BASE

### Supported by Research
| Claim | Source |
|-------|--------|
| Retrieval practice > restudy | Roediger & Karpicke (2006) |
| Spaced > massed practice | Cepeda et al. (2006) |
| Testing + distributed practice high-utility | Dunlosky et al. (2013) |

### Heuristics (Not Yet Cited)
- 1-3-7-21 spaced retrieval schedule
- 3+2 rotational interleaving
- Exit ticket format
- R/Y/G retrospective timetable

---

## PART 11: KNOWN PITFALLS

**Encoding Errors:**
- Jumping ahead before confirming imagery
- Image not tied to meaning/function
- Missing "word + meaning together" step
- KWIK flow not followed (Sound→Function→Image→Lock)

**Progression Errors:**
- Recognition ≠ Recall (must L2 teach-back before L4)
- Skipping planning phase
- Teaching without source-lock

**Session Errors:**
- No wrap/exit ticket
- No cards for misses
- Overconfidence without retrieval check

---

## APPENDIX: FILE LOCATIONS

### Canonical Sources (sop/src/)
- `modules/M0-M6.md` - Execution protocols
- `frameworks/` - PEIRRO, KWIK, H/M/Y-series, Levels
- `engines/` - Anatomy Engine, Concept Engine
- `templates/` - Exit ticket, retrospective timetable, session log
- `evidence/` - Evidence base, research index

### Runtime (gpt_bundle_v9.3/)
- `1_Project_Files/` - Knowledge upload files
- `2_Instructions/` - Custom instructions
- `3_Prompts/` - Runtime prompts

### Legacy (sop/archive/)
- v8.6, v9.1 modules (superseded)
- Old runtime files (deprecated)

---

*Last updated: v9.3 | Compiled from full repo audit*
