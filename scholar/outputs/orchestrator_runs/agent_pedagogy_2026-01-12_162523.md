Ledger Snapshot: Goal: generate pedagogy effectiveness questions for run `2026-01-12_162523` using `scholar/knowledge/pedagogy_audit.md`; Now: delivering response; Next: await further instructions; Open Questions: none.

## Summary
With no telemetry snapshot available, these questions target the highest-risk rubric requirements that cannot be verified without evidence, ensuring the pedagogy audit can be grounded in measurable signals.

## Questions Needed
- Retrieval Practice checklist: What log evidence shows questions are asked before explanations for each content chunk (signal: item sequence timestamps or role tags), and what proportion of chunks comply?
- Retrieval Practice checklist: Is there a consistent retrieval-feedback-retest cycle after errors (signal: error -> feedback -> retest events in session logs), and where is that captured?
- Spaced Practice checklist: Where are "next review" timestamps stored, and what is the coverage rate per session (signal: `next_review_at` field or scheduler output)?
- Spaced Practice checklist: How are prior-session errors resurfaced in current sessions (signal: reuse of past error IDs or resurfacing tags)?
- Interleaving checklist: Do quiz items alternate topics or levels (signal: topic sequence distribution / switch rate in quiz logs)?
- Feedback Quality checklist: Is feedback immediate and corrective after incorrect responses (signal: response-to-feedback latency and presence of explanatory text)?
- Errorful Learning checklist: Are errors labeled by type (Conceptual vs Recall) and is rollback triggered on repeats (signal: `error_type` field and rollback events)?
- Transfer & Application checklist: How often do sessions include clinical vignettes or functional behavior checks (signal: vignette/H2 tags in prompts)?
- Cognitive Load checklist: Is output delivered in step-by-step form with fading cues as mastery increases (signal: instruction length, cue-count trends vs mastery level)?
- Metacognition checklist: Are confidence ratings and Wrap reflections captured (signal: confidence/reflection fields per session)?
- Source Grounding checklist (Source-Lock M0): Are factual claims withheld or cited until Source Packet is present (signal: citation format presence and refusal events when sources missing)?
- Output Rule: Do pedagogy audits include exactly one primary recommendation (signal: recommendation count per audit artifact)?

## Suggested Measurements
- Question-before-explanation compliance rate per session (percent of chunks where question precedes explanation).
- Retrieval-feedback-retest completion rate and median feedback latency (seconds).
- Next-review timestamp coverage and scheduled interval distribution.
- Error resurfacing rate (percent of current-session items linked to prior errors).
- Interleaving index (topic switch rate per N items; entropy of topic sequence).
- Corrective feedback rate (percent of incorrect responses with "why" explanation).
- Error typing distribution and rollback frequency for repeated errors.
- Clinical vignette / H2 behavior prompt rate per session.
- Cue density vs mastery trend (average hints per item by mastery level).
- Confidence/reflection completion rate in Wrap phase.
- Source-Lock compliance: citation coverage for factual claims; refusal count when sources missing.
- Audit output compliance: recommendation count per audit artifact.