#!/usr/bin/env python3
from __future__ import annotations

import re
import sys
from pathlib import Path
from typing import Iterable, List

VERSION = "9.3"

ROOT = Path(__file__).resolve().parents[2]
SOP_DIR = ROOT / "sop"
LIB_DIR = SOP_DIR / "library"
RUNTIME_DIR = SOP_DIR / "runtime"
UPLOAD_DIR = RUNTIME_DIR / "knowledge_upload"


def rel(path: Path) -> str:
    return path.relative_to(ROOT).as_posix()


def read_text(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def normalize(text: str) -> str:
    return text.replace("\r\n", "\n").replace("\r", "\n").strip()


def strip_relative_links(text: str) -> str:
    def repl(match: re.Match[str]) -> str:
        label = match.group(1)
        link = match.group(2)
        if re.match(r"^(https?://|mailto:)", link):
            return match.group(0)
        return label

    return re.sub(r"\[([^\]]+)\]\(([^)]+)\)", repl, text)


def replace_local_refs(text: str) -> str:
    replacements = {
        "sop/src/templates/retrospective_timetable.md": "retrospective timetable (see Templates section)",
        "sop/src/templates/post_lecture_elaboration_prompts.md": "post-lecture elaboration prompts (see Templates section)",
        "sop/logging_schema_v9.3.md": "logging schema (see Logging section)",
        "logging_schema_v9.3.md": "logging schema (see Logging section)",
        "sop/src/workload/rotational_interleaving_3plus2.md": "3+2 rotational interleaving (see M0 Planning)",
        "sop/master_rotational_interleaving_system.md": "3+2 rotational interleaving (see M0 Planning)",
        "09-templates.md": "Templates section",
        "06-modes.md": "Modes section",
    }
    for key, value in replacements.items():
        text = text.replace(key, value)
    return text


def sanitize(text: str) -> str:
    text = normalize(text)
    text = strip_relative_links(text)
    text = replace_local_refs(text)
    return text


def extract_section(text: str, heading: str) -> str:
    text = normalize(text)
    lines = text.split("\n")
    for i, line in enumerate(lines):
        if line.strip() == heading:
            level = len(line.split()[0])
            start = i
            end = len(lines)
            for j in range(i + 1, len(lines)):
                candidate = lines[j].strip()
                if candidate.startswith("#"):
                    candidate_level = len(candidate.split()[0])
                    if candidate_level <= level:
                        end = j
                        break
            return "\n".join(lines[start:end]).strip()
    raise ValueError(f"Heading not found: {heading}")


def join_sections(text: str, headings: Iterable[str]) -> str:
    return "\n\n".join(extract_section(text, heading) for heading in headings)


def find_wrap_heading(text: str) -> str:
    text = normalize(text)
    lines = text.split("\n")
    prefix = "## M6: Wrap"
    for line in lines:
        stripped = line.strip()
        if stripped.startswith(prefix):
            print(f"Wrap section found: {stripped}")
            return stripped
    raise ValueError(
        "M6 Wrap heading not found. Acceptable headings: "
        "'## M6: Wrap (Close and Schedule)', '## M6: Wrap', "
        "or any heading starting with '## M6: Wrap'."
    )


def render_header(filename: str, sources: List[Path]) -> str:
    sources_block = "\n".join(f"- {rel(path)}" for path in sources)
    return (
        f"# Runtime Bundle: {filename}\n"
        f"Version: v{VERSION}\n"
        "Generated by: sop/tools/build_runtime_bundle.py (deterministic)\n"
        f"Sources:\n{sources_block}\n\n---\n\n"
    )


def render_source_block(source_path: Path, content: str) -> str:
    return f"## Source: {rel(source_path)}\n\n{sanitize(content)}\n"


def write_output(path: Path, content: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content.strip() + "\n", encoding="utf-8")


def build_index_and_rules(core_rules: str, evidence: str) -> str:
    core_extract = join_sections(
        core_rules,
        [
            "## Session Rules",
            "## Content Rules",
            "## Evidence Nuance Rules",
            "## Logging Rules",
            "## No-Skip Rules (Summary)",
        ],
    )
    notebooklm = extract_section(evidence, "## NotebookLM Bridge")

    additions = """
## Source of Truth
- Canonical content lives in `sop/library/` and is read-only.
- Runtime files in `sop/runtime/knowledge_upload/` are generated. Do not edit them directly.

## Bundle Index (upload in order)
1) 00_INDEX_AND_RULES.md
2) 01_MODULES_M0-M6.md
3) 02_FRAMEWORKS.md
4) 03_ENGINES.md
5) 04_LOGGING_AND_TEMPLATES.md
6) 05_EXAMPLES_MINI.md

## Canonical Library Map (current filenames)
- 02-learning-cycle.md (PEIRRO + KWIK)
- 03-frameworks.md (H/M/Y/L)
- 04-engines.md
- 05-session-flow.md (M0-M6)
- 06-modes.md
- 08-logging.md
- 09-templates.md
- 11-examples.md
- 12-evidence.md

## Multi-Domain Topic Prefix + Engine Router (schema-safe)
- The `topic` field must be prefixed with: `[DPT]` or `[Startup]` or `[Other]`.
- Engine router:
  - If `[DPT]` and regional/spatial anatomy, use the Anatomy Engine.
  - Otherwise use the Concept Engine.
- Do not add new JSON keys for domain routing.

## UNVERIFIED Behavior (no refusal)
- If sources are missing or no NotebookLM Source Packet is provided, mark outputs **UNVERIFIED**.
- Limit output to strategy, questions, and planning until sources are provided.

## Dashboard Ingest: `anki_cards` Encoding
- Enhanced JSON field `anki_cards` is a semicolon-separated list.
- Each card uses the format: `Front|||Back|||TagsCSV|||Deck`.
- Avoid semicolons inside Front/Back.
- Deck may be `AUTO` to route by topic prefix.
"""

    return (
        sanitize(additions)
        + "\n\n"
        + render_source_block(LIB_DIR / "01-core-rules.md", core_extract)
        + "\n"
        + render_source_block(LIB_DIR / "12-evidence.md", notebooklm)
    )


def build_modules(session_flow: str, modes: str) -> str:
    wrap_heading = find_wrap_heading(session_flow)
    headings = [
        "## Pre-Session: Material Ingestion",
        "## 60-Second Quick Start",
        "## M0: Planning",
        "## M1: Entry",
        "## M2: Prime (Map the Territory)",
        "## M3: Encode (Attach Meaning)",
        "## M4: Build (Practice and Transfer)",
        wrap_heading,
        "## Quick Reference: Session Flow",
    ]
    session_extract = join_sections(session_flow, headings)
    return (
        render_source_block(LIB_DIR / "05-session-flow.md", session_extract)
        + "\n"
        + render_source_block(LIB_DIR / "06-modes.md", modes)
    )


def build_frameworks(learning_cycle: str, frameworks: str) -> str:
    return (
        render_source_block(LIB_DIR / "02-learning-cycle.md", learning_cycle)
        + "\n"
        + render_source_block(LIB_DIR / "03-frameworks.md", frameworks)
    )


def build_engines(engines: str) -> str:
    router = """
## Engine Router (Multi-Domain)
- Topic prefix required: `[DPT]` / `[Startup]` / `[Other]`.
- If `[DPT]` and regional/spatial anatomy: use Anatomy Engine.
- Otherwise: use Concept Engine.
- This is a routing convention only; no schema keys are added.
"""
    return sanitize(router) + "\n\n" + render_source_block(LIB_DIR / "04-engines.md", engines)


def build_logging(logging: str, templates: str) -> str:
    additions = """
## Runtime Additions (v9.3)

### Topic Prefix (multi-domain)
- `topic` must start with `[DPT]`, `[Startup]`, or `[Other]`.

### Dashboard `anki_cards` Encoding
- `anki_cards` remains a semicolon-separated list.
- Each card entry is: `Front|||Back|||TagsCSV|||Deck`.
- Avoid semicolons inside Front/Back.
- Deck may be `AUTO` to route by topic prefix.
"""
    return (
        sanitize(additions)
        + "\n\n"
        + render_source_block(LIB_DIR / "08-logging.md", logging)
        + "\n"
        + render_source_block(LIB_DIR / "09-templates.md", templates)
    )


def build_examples(examples: str) -> str:
    headings = [
        "## Command Reference",
        "## Example: Session Start (Planning)",
        "## Example: Sprint Mode (Fail-First)",
        "## Example: Wrap Output",
    ]
    sections: list[str] = []
    missing: list[str] = []
    for heading in headings:
        try:
            sections.append(extract_section(examples, heading))
        except ValueError:
            missing.append(heading)
    if missing:
        print(
            "WARNING: Missing example headings: " + ", ".join(missing),
            file=sys.stderr,
        )
    extract = "\n\n".join(sections).strip()
    return render_source_block(LIB_DIR / "11-examples.md", extract)


def build_runtime_prompt() -> str:
    return sanitize(
        f"""## Runtime Prompt (Paste at Session Start)

Structured Architect v{VERSION} active.
Role: guide active construction; enforce Seed-Lock; adapt to learner readiness.

---
## Planning Phase (FIRST)
Before any teaching:
1) TARGET: exam/block + time available
2) POSITION: covered vs remaining; weak spots
3) MATERIALS: LOs, slides, labs, practice Qs, notes
4) SOURCE-LOCK: list specific materials used today (pages/links)
5) INTERLEAVE: 1-2 weak anchors from prior session
6) PLAN OF ATTACK: 3-5 steps
7) GLOSSARY SCAN: top 5 terms defined at L2
8) PRIME: 1-3 pre-questions or 60-120s brain dump
9) TOPIC PREFIX: `[DPT]` / `[Startup]` / `[Other]` (required)

No teaching starts until target, sources, plan, and pre-test are locked.
NotebookLM Source Packet required for factual teaching. If missing, mark outputs UNVERIFIED and limit to strategy/questions.

Engine router:
- If `[DPT]` and regional/spatial anatomy -> Anatomy Engine
- Else -> Concept Engine

---
## Entry Questions
- Focus level (1-10)
- Energy/motivation
- Mode: Core / Sprint / Light / Quick Sprint / Drill
- Resuming? Paste resume or summarize where you left off

---
## Anatomy Sessions
Mandatory order:
BONES -> LANDMARKS -> ATTACHMENTS -> ACTIONS -> NERVES -> ARTERIAL SUPPLY -> CLINICAL

Rules:
- Visual-first landmarks; rollback if OIANA+ recall fails.
- `mnemonic` command available only after understanding; provide 3 options.
- Image recall drill: unlabeled -> identify -> reveal -> misses become cards.

---
## Commands
| Say | Does |
| --- | --- |
| plan | Start/review planning |
| ready / next | Next step |
| bucket | Group/organize |
| mold | Fix my thinking |
| wrap | End session |
| draw [structure] | Drawing instructions |
| landmark | Landmark pass |
| rollback | Back to earlier phase |
| mode core/sprint/drill/light/quick-sprint | Switch mode |
| mnemonic | 3 mnemonic options (after understanding) |
| menu | Show commands |

---
## Wrap Output (MANDATORY)
At Wrap, output:
1) Exit ticket (blurt, muddiest point, next action hook)
2) Spaced retrieval schedule (1-3-7-21; adjust by red/yellow/green status)
3) Tracker JSON + Enhanced JSON per logging schema v9.3
4) `anki_cards` encoding: `Front|||Back|||TagsCSV|||Deck` (cards separated by semicolons; Deck may be AUTO)

---
Ready when you are. What is your target and what materials do you have?
"""
    )


def build_runtime_bundle() -> None:
    required = {
        "00-overview.md",
        "01-core-rules.md",
        "02-learning-cycle.md",
        "03-frameworks.md",
        "04-engines.md",
        "05-session-flow.md",
        "06-modes.md",
        "08-logging.md",
        "09-templates.md",
        "11-examples.md",
        "12-evidence.md",
    }
    missing = [name for name in required if not (LIB_DIR / name).exists()]
    if missing:
        raise FileNotFoundError(f"Missing library files: {', '.join(missing)}")

    core_rules = read_text(LIB_DIR / "01-core-rules.md")
    evidence = read_text(LIB_DIR / "12-evidence.md")
    session_flow = read_text(LIB_DIR / "05-session-flow.md")
    modes = read_text(LIB_DIR / "06-modes.md")
    learning_cycle = read_text(LIB_DIR / "02-learning-cycle.md")
    frameworks = read_text(LIB_DIR / "03-frameworks.md")
    engines = read_text(LIB_DIR / "04-engines.md")
    logging = read_text(LIB_DIR / "08-logging.md")
    templates = read_text(LIB_DIR / "09-templates.md")
    examples = read_text(LIB_DIR / "11-examples.md")

    outputs = {
        "00_INDEX_AND_RULES.md": (
            [LIB_DIR / "01-core-rules.md", LIB_DIR / "12-evidence.md"],
            build_index_and_rules(core_rules, evidence),
        ),
        "01_MODULES_M0-M6.md": (
            [LIB_DIR / "05-session-flow.md", LIB_DIR / "06-modes.md"],
            build_modules(session_flow, modes),
        ),
        "02_FRAMEWORKS.md": (
            [LIB_DIR / "02-learning-cycle.md", LIB_DIR / "03-frameworks.md"],
            build_frameworks(learning_cycle, frameworks),
        ),
        "03_ENGINES.md": (
            [LIB_DIR / "04-engines.md"],
            build_engines(engines),
        ),
        "04_LOGGING_AND_TEMPLATES.md": (
            [LIB_DIR / "08-logging.md", LIB_DIR / "09-templates.md"],
            build_logging(logging, templates),
        ),
        "05_EXAMPLES_MINI.md": (
            [LIB_DIR / "11-examples.md"],
            build_examples(examples),
        ),
    }

    for filename, (sources, body) in outputs.items():
        content = render_header(filename, sources) + body
        write_output(UPLOAD_DIR / filename, content)

    runtime_prompt = build_runtime_prompt()
    prompt_header = (
        f"# Runtime Prompt\nVersion: v{VERSION}\n"
        "Generated by: sop/tools/build_runtime_bundle.py (deterministic)\n"
        "Sources: sop/library (multiple)\n\n---\n\n"
    )
    write_output(RUNTIME_DIR / "runtime_prompt.md", prompt_header + runtime_prompt)


if __name__ == "__main__":
    try:
        build_runtime_bundle()
    except Exception as exc:
        print(f"ERROR: {exc}", file=sys.stderr)
        sys.exit(1)
    print("Runtime bundle generated in sop/runtime/knowledge_upload/ and sop/runtime/runtime_prompt.md")
