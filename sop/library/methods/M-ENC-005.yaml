id: M-ENC-005
name: Why-Chain
category: encode
description: Ask 'why?' 3-5 times in succession about a concept to build causal depth. Each answer becomes the premise for the next question. Based on elaborative interrogation (Dunlosky et al.).
default_duration_min: 5
energy_cost: medium
best_stage: first_exposure
control_stage: ENCODE
status: validated
tags:
  - elaboration
  - causal
  - depth
  - evidence-based
mechanisms:
  - elaboration
  - generation
inputs:
  - Initial statement or fact to interrogate
  - Source material for verification
steps:
  - step: 1
    action: Write the initial statement/fact
    notes: "Example: 'ACE inhibitors cause cough'"
  - step: 2
    action: "Ask: 'Why is this true?'"
    notes: Write the answer as a new statement
  - step: 3
    action: "Ask 'why?' about your answer"
    notes: Go one level deeper
  - step: 4
    action: Repeat until you hit 3-5 levels or bedrock knowledge
    notes: Bedrock = can't explain further without new learning
  - step: 5
    action: Verify chain accuracy with source material
    notes: Flag any errors for correction
outputs:
  - Why-chain document (3-5 linked explanations)
  - Depth level reached
  - Verification status
stop_criteria:
  - 3-5 why levels completed
  - Hit bedrock knowledge
  - Chain verified against source
failure_modes:
  - mode: Circular reasoning
    mitigation: Each answer must introduce new information
  - mode: Stopping too early
    mitigation: Require minimum 3 levels
  - mode: Making up explanations
    mitigation: Verify each level against source
logging_fields:
  - initial_statement
  - chain_depth
  - verification_status
  - bedrock_reached
evidence:
  citation: Dunlosky et al. (2013)
  finding: Elaborative interrogation rated moderate utility for learning; builds causal understanding
  source: seed_methods.py
evidence_raw: Dunlosky et al. (2013); elaborative interrogation rated moderate utility for learning

facilitation_prompt: |
  You are running this method card in its assigned control stage. Execute only what this card defines.

  Operational instructions:
  1) Confirm required inputs from the card before starting. If inputs are missing, request only the minimum missing input.
  2) Follow the listed steps in order and keep output concise, structured, and actionable.
  3) Enforce control-stage boundaries:
     - PRIME: orientation and structure only; no scored checks or hidden calibration.
     - CALIBRATE: measure current state with confidence + performance signals.
     - ENCODE: force active processing; avoid passive lecture-only output.
     - REFERENCE: build concrete anchors/artifacts before any retrieval demand.
     - RETRIEVE: require learner attempt before revealing full answers.
     - OVERLEARN: run bounded fluency reps and stop at fatigue/cap criteria.
  4) Produce the outputs/artifacts listed on this card.
  5) Stop when stop_criteria are met and log required telemetry fields.
