id: M-PRE-005
name: Concept Cluster
category: prepare
description: Group related terms/concepts into 3-5 clusters. Identify hierarchy and relationships.
default_duration_min: 5
energy_cost: medium
best_stage: first_exposure
control_stage: PRIME
status: validated
tags:
  - organization
  - visual
  - grouping
  - chunking
mechanisms:
  - elaboration
  - discrimination
inputs:
  - List of terms/concepts from the topic (10-20 items)
  - Blank paper or whiteboard
steps:
  - step: 1
    action: List all key terms from the topic
    notes: Extract from headings, bold text, or term lists
  - step: 2
    action: Sort terms into 3-5 natural groupings
    notes: "Look for: shared function, shared location, shared mechanism"
  - step: 3
    action: Name each cluster with a descriptive label
    notes: The label should capture what unifies the group
  - step: 4
    action: Arrange clusters spatially to show relationships
    notes: Related clusters closer together; hierarchies top-to-bottom
  - step: 5
    action: Draw connecting lines between related clusters
    notes: Label connections with relationship type
outputs:
  - Cluster diagram (3-5 labeled groups)
  - Inter-cluster relationships mapped
  - Visual organization of topic
stop_criteria:
  - All terms assigned to clusters
  - Clusters named
  - 5 minutes elapsed
failure_modes:
  - mode: Too many clusters (>5)
    mitigation: Force consolidation; look for super-categories
  - mode: Clusters too uneven (one has 80% of terms)
    mitigation: Split large clusters by sub-function
  - mode: Terms don't fit any cluster
    mitigation: Create "Misc" cluster; these may be edge cases or prerequisites
logging_fields:
  - cluster_count
  - terms_per_cluster
  - inter_cluster_connections
evidence:
  citation: Bower et al. (1969)
  finding: Conceptual organization improves recall by 2-3x compared to random presentation
  source: seed_methods.py
evidence_raw: Bower et al. (1969); conceptual organization improves recall by 2-3x

facilitation_prompt: |
  You are running this method card in its assigned control stage. Execute only what this card defines.

  Operational instructions:
  1) Confirm required inputs from the card before starting. If inputs are missing, request only the minimum missing input.
  2) Follow the listed steps in order and keep output concise, structured, and actionable.
  3) Enforce control-stage boundaries:
     - PRIME: orientation and structure only; no scored checks or hidden calibration.
     - CALIBRATE: measure current state with confidence + performance signals.
     - ENCODE: force active processing; avoid passive lecture-only output.
     - REFERENCE: build concrete anchors/artifacts before any retrieval demand.
     - RETRIEVE: require learner attempt before revealing full answers.
     - OVERLEARN: run bounded fluency reps and stop at fatigue/cap criteria.
  4) Produce the outputs/artifacts listed on this card.
  5) Stop when stop_criteria are met and log required telemetry fields.
